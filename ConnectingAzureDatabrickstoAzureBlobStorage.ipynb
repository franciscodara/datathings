{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting Azure Databricks to Azure Blob Storage\n",
    "\n",
    "storage_account_name = \"\"\n",
    "storage_account_key = \"\"\n",
    "container = \"\"\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\", storage_account_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.ls(f\"wasbs://{container}@databricksdemostorage.blob.core.windows.net/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%fs ls wasbs://input@databricksdemostorage.blob.core.windows.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"delimiter\", \",\") \\\n",
    "  .csv(f\"wasbs://{container}@{storage_account_name}.blob.core.windows.net/retrain_housing_data.csv\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.mount(\n",
    "  source = f\"wasbs://{container}@{storage_account_name}.blob.core.windows.net\",\n",
    "  mount_point = \"/mnt/azureStorage\",\n",
    "  extra_configs = {f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\": storage_account_key}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.mounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbutils.fs.unmount(\"/mnt/azureStorage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%fs ls \"dbfs:/mnt/azureStorage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"delimiter\", \",\") \\\n",
    "  .csv(\"/mnt/azureStorage/retrain_housing_data.csv\")\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.createDataFrame([(-114.42, 35.1, 11.0, 325.0, 94.0, 1212.0, 52.0, 5.22, 301500, \"INLAND\")], [\"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\", \"total_bedrooms\", \"population\", \"households\", \"median_income\", \"median_house_value\", \"ocean_proximity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.write.csv(f\"wasbs://{container}@{storage_account_name}.blob.core.windows.net/new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.ls(f\"wasbs://{container}@{storage_account_name}.blob.core.windows.net/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = data.toPandas()\n",
    "pandas_df.to_csv(\"/dbfs/FileStore/tables/pandas.csv\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%fs ls dbfs:/FileStore/tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.library.installPyPI(\"azure.storage.blob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = BlobClient.from_connection_string(connection, container_name=\"\", blob_name=\"pandas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/dbfs/FileStore/tables/pandas.csv\", \"rb\") as f:\n",
    "  client.upload_blob(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%fs ls wasbs://input@databricksdemostorage.blob.core.windows.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = client.download_blob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.content_as_text()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
